{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the Pickle Data File and Drop Duplicate Smple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Formula</th>\n",
       "      <th>Mag_atom</th>\n",
       "      <th>Near_Distance</th>\n",
       "      <th>SGR</th>\n",
       "      <th>Tc_avg</th>\n",
       "      <th>Tc_std</th>\n",
       "      <th>material_id</th>\n",
       "      <th>Tol_DOS</th>\n",
       "      <th>Fe_dDOS</th>\n",
       "      <th>Cr_dDOS</th>\n",
       "      <th>...</th>\n",
       "      <th>Co_dDOS</th>\n",
       "      <th>Coordnate_Number</th>\n",
       "      <th>Magnetic_moment</th>\n",
       "      <th>Bound_Length</th>\n",
       "      <th>lattice_a</th>\n",
       "      <th>lattice_b</th>\n",
       "      <th>lattice_c</th>\n",
       "      <th>lattice_alpha</th>\n",
       "      <th>lattice_beta</th>\n",
       "      <th>lattice_gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AlAu2Mn</td>\n",
       "      <td>Mn</td>\n",
       "      <td>4.495784914784067</td>\n",
       "      <td>225</td>\n",
       "      <td>216.50</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>mp-5491</td>\n",
       "      <td>0.206274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>4.528144</td>\n",
       "      <td>4.528144</td>\n",
       "      <td>4.528144</td>\n",
       "      <td>4.528144</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AlB2Fe2</td>\n",
       "      <td>Fe</td>\n",
       "      <td>2.6858372440369473</td>\n",
       "      <td>65</td>\n",
       "      <td>288.00</td>\n",
       "      <td>13.735599</td>\n",
       "      <td>mp-3805</td>\n",
       "      <td>0.132829</td>\n",
       "      <td>0.099305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.013000</td>\n",
       "      <td>2.785664</td>\n",
       "      <td>2.863114</td>\n",
       "      <td>2.915233</td>\n",
       "      <td>5.695537</td>\n",
       "      <td>104.828257</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AlCCr2</td>\n",
       "      <td>Cr</td>\n",
       "      <td>2.7526898308246373</td>\n",
       "      <td>194</td>\n",
       "      <td>73.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>mp-9956</td>\n",
       "      <td>0.158591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.751682</td>\n",
       "      <td>2.843004</td>\n",
       "      <td>2.843004</td>\n",
       "      <td>12.707956</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AlCMn3</td>\n",
       "      <td>Mn</td>\n",
       "      <td>2.738058878110549</td>\n",
       "      <td>221</td>\n",
       "      <td>294.25</td>\n",
       "      <td>9.120718</td>\n",
       "      <td>mp-4593</td>\n",
       "      <td>0.127507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.407333</td>\n",
       "      <td>2.691674</td>\n",
       "      <td>3.806601</td>\n",
       "      <td>3.806601</td>\n",
       "      <td>3.806601</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Al2Ce2Co15</td>\n",
       "      <td>Co</td>\n",
       "      <td>2.436418136336501</td>\n",
       "      <td>166</td>\n",
       "      <td>751.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>mp-16484</td>\n",
       "      <td>1.120249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823275</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>2.475784</td>\n",
       "      <td>6.325907</td>\n",
       "      <td>6.325907</td>\n",
       "      <td>6.325907</td>\n",
       "      <td>82.507456</td>\n",
       "      <td>82.507456</td>\n",
       "      <td>82.507456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Formula Mag_atom       Near_Distance  SGR  Tc_avg     Tc_std  \\\n",
       "0      AlAu2Mn       Mn   4.495784914784067  225  216.50  16.500000   \n",
       "3      AlB2Fe2       Fe  2.6858372440369473   65  288.00  13.735599   \n",
       "5       AlCCr2       Cr  2.7526898308246373  194   73.00   0.000000   \n",
       "8       AlCMn3       Mn   2.738058878110549  221  294.25   9.120718   \n",
       "16  Al2Ce2Co15       Co   2.436418136336501  166  751.00   0.000000   \n",
       "\n",
       "   material_id   Tol_DOS   Fe_dDOS   Cr_dDOS  ...   Co_dDOS  Coordnate_Number  \\\n",
       "0      mp-5491  0.206274  0.000000  0.000000  ...  0.000000               6.0   \n",
       "3      mp-3805  0.132829  0.099305  0.000000  ...  0.000000               4.0   \n",
       "5      mp-9956  0.158591  0.000000  0.130603  ...  0.000000               4.5   \n",
       "8      mp-4593  0.127507  0.000000  0.000000  ...  0.000000               8.0   \n",
       "16    mp-16484  1.120249  0.000000  0.000000  ...  0.823275               8.0   \n",
       "\n",
       "    Magnetic_moment  Bound_Length  lattice_a  lattice_b  lattice_c  \\\n",
       "0          0.005000      4.528144   4.528144   4.528144   4.528144   \n",
       "3         -0.013000      2.785664   2.863114   2.915233   5.695537   \n",
       "5          0.000000      2.751682   2.843004   2.843004  12.707956   \n",
       "8         -0.407333      2.691674   3.806601   3.806601   3.806601   \n",
       "16         1.180000      2.475784   6.325907   6.325907   6.325907   \n",
       "\n",
       "    lattice_alpha  lattice_beta  lattice_gamma  \n",
       "0       60.000000     60.000000      60.000000  \n",
       "3      104.828257     90.000000      90.000000  \n",
       "5       90.000000     90.000000     120.000000  \n",
       "8       90.000000     90.000000      90.000000  \n",
       "16      82.507456     82.507456      82.507456  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "with open('feature.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "data = data.drop_duplicates(subset = 'material_id')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only Keep Important Features in Table: \n",
    "- Density of state related: \n",
    "    - Tol_DOS, Fe_dDOS, Cr_dDOS, Mn_dDOS, Co_dDOS\n",
    "- Crystal structure related: \n",
    "    - Coordnate_Number, Magnetic_moment,  Bound_Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of this tab is (317, 15)\n"
     ]
    }
   ],
   "source": [
    "## get rid off nuisance features and drop NAN\n",
    "tab = data.drop(['Formula', 'Mag_atom', 'Near_Distance', 'Tc_std','material_id','SGR'],axis = 1)\n",
    "tab = tab.dropna(axis=0)\n",
    "print(\"The dimension of this tab is\", tab.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "- Apply standard feature **(StandardScaler)** scaling\n",
    "    - z = (x - u)/s\n",
    "    - x is the data point to be scale and u is the mean of data set and s is the standard deviation **(std)\n",
    "    - The default behavior of is centering the data first and then scaling the data to unit std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar = StandardScaler(copy = True, with_mean = True, with_std = True)\n",
    "\n",
    "for i in range(tab.shape[1]):\n",
    "    feature = np.array(tab.iloc[:,i]).reshape(tab.shape[0],1)\n",
    "    tab.iloc[:,i] = scalar.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Pair Correlation Between Features###\n",
    "- High correlcation between 'Tol_DOS' and 'Fe_dDOS' and 'Co_dDOS' \n",
    "- Shows that there is more samples contains Fe and Co element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1cfb6940>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (7, 7), dpi = 100)\n",
    "sn.heatmap(tab.corr(), annot = True, annot_kws = dict(fontsize = 11), fmt = '.1f', cmap = 'YlGnBu', linewidths=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the Orders of Sample, and Separate the Table to Input \"X\" and Lable \"Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = tab.sample(frac = 1, random_state = 5).reset_index(drop = True)\n",
    "X = tab.drop('Tc_avg', axis = 1)\n",
    "Y = pd.DataFrame(tab['Tc_avg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import models: ###\n",
    "- Support Vector Regression\n",
    "- Kernel Ridge Regression \n",
    "- Random Forest \n",
    "- Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Grid Search with 5 Folds Cross Validation\n",
    "- Using R square and and explained_variance_score as metric for this regression model \n",
    "- reference for Train/Test Split and Cross Validation\n",
    "    - https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6\n",
    "\n",
    "### Define The Functions For Implementing Grid Search and Report Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "pd.options.display.max_colwidth = 500\n",
    "\n",
    "def report_grid_search(search_result, parameters, show_number):\n",
    "    print(\"best_socres = %.3f \"% search_result.best_score_)\n",
    "    print(\"best_parameters = %r\" %search_result.best_params_)\n",
    "    \n",
    "    means = search_result.cv_results_['mean_test_score']\n",
    "    stds = search_result.cv_results_['std_test_score']\n",
    "    params = search_result.cv_results_['params']\n",
    "    \n",
    "    results = pd.DataFrame({'means': means, \"stds\": stds, \"params\": params})\n",
    "    results = results.sort_values(by = ['means'], ascending = False)\n",
    "    display(HTML(results.head(show_number).to_html()))\n",
    "\n",
    "def grid_search(model, parameters, X, Y):\n",
    "    scorer = make_scorer(r2_score, greater_is_better = True)\n",
    "    grid_search = GridSearchCV(model, parameters, cv = 5, scoring = scorer)\n",
    "    grid_search.fit(X, Y)\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuned Parameters for Support Vector Regression (SVR) Model\n",
    "- **Gamma**: Kernel coefficient for rbf, must be greater than 0.\n",
    "- **C**: Penalty parameter C of the error term.\n",
    "- **Epsilon**: a margin of tolerance (epsilon).\n",
    "- **Url**: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_socres = 0.406 \n",
      "best_parameters = {'C': 5.000000000000002, 'epsilon': 0.2, 'gamma': 0.03}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>means</th>\n",
       "      <th>stds</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3636</th>\n",
       "      <td>0.406148</td>\n",
       "      <td>0.151820</td>\n",
       "      <td>{'C': 5.000000000000002, 'epsilon': 0.2, 'gamma': 0.03}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>0.406034</td>\n",
       "      <td>0.152226</td>\n",
       "      <td>{'C': 4.900000000000002, 'epsilon': 0.2, 'gamma': 0.03}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3816</th>\n",
       "      <td>0.405950</td>\n",
       "      <td>0.151862</td>\n",
       "      <td>{'C': 5.100000000000001, 'epsilon': 0.2, 'gamma': 0.03}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276</th>\n",
       "      <td>0.405868</td>\n",
       "      <td>0.152611</td>\n",
       "      <td>{'C': 4.800000000000002, 'epsilon': 0.2, 'gamma': 0.03}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>0.405544</td>\n",
       "      <td>0.153146</td>\n",
       "      <td>{'C': 4.700000000000001, 'epsilon': 0.2, 'gamma': 0.03}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = [{'C': np.arange(3, 6, 0.1), 'epsilon': np.arange(0, 1, 0.05), 'gamma': np.arange(0.03, 0.07, 0.005) }]\n",
    "model = SVR(kernel = 'rbf')\n",
    "SVR_grid_search = grid_search(model, parameters, X, Y)\n",
    "report_grid_search(SVR_grid_search, parameters, show_number = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuned Parameters for Kernel Ridge Regression (KRR) Model\n",
    "- **Alpha**: Penalty parameter to improve the conditioning of the problem and reduce the variance of the estimates.\n",
    "- **Gamma**: Coefficient for the kernel.\n",
    "-  **Url**:https://scikitlearn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html#sklearn.kernel_ridge.KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_socres = 0.481 \n",
      "best_parameters = {'alpha': 0.07, 'gamma': 0.02299999999999999}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>means</th>\n",
       "      <th>stds</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.480595</td>\n",
       "      <td>0.070253</td>\n",
       "      <td>{'alpha': 0.07, 'gamma': 0.02299999999999999}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.480572</td>\n",
       "      <td>0.070286</td>\n",
       "      <td>{'alpha': 0.07, 'gamma': 0.021999999999999992}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.480565</td>\n",
       "      <td>0.070217</td>\n",
       "      <td>{'alpha': 0.07, 'gamma': 0.023999999999999987}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.480523</td>\n",
       "      <td>0.069365</td>\n",
       "      <td>{'alpha': 0.06, 'gamma': 0.01999999999999999}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.480510</td>\n",
       "      <td>0.071138</td>\n",
       "      <td>{'alpha': 0.08, 'gamma': 0.02599999999999999}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = [{'alpha': np.arange(0, 0.1, 0.01), 'gamma': np.arange(0.01, 0.03, 0.001) }]\n",
    "model = KernelRidge(kernel = 'laplacian')\n",
    "KRR_grid_search = grid_search(model, parameters, X, Y)\n",
    "report_grid_search(KRR_grid_search, parameters, show_number = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuned Parameters for Random Forest Regression Model (RFR)\n",
    "- **n_estimators**: The number of trees in the forest.\n",
    "- **max_depth**: The maximum depth of the tree. \n",
    "- **min_samples_split**: The minimum number of samples required to split an internal node.\n",
    "- **url**: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_socres = 0.482 \n",
      "best_parameters = {'max_depth': 10, 'n_estimators': 1000}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>means</th>\n",
       "      <th>stds</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.482233</td>\n",
       "      <td>0.103917</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 1000}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = {'max_depth': [10], 'n_estimators': [1000]}\n",
    "model = RandomForestRegressor(random_state = 3)\n",
    "RFG_grid_search = grid_search(model, parameters, X, Y)\n",
    "report_grid_search(RFG_grid_search, parameters, show_number = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learning ##\n",
    "- **Bagging:** Average the outputs of above four model to produce the prediction\n",
    "    - **url:** https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n",
    "- **Stacking:** combine above four models by training a linear regression model\n",
    "\n",
    "## Define Functions For Ensemble Learning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble.voting import VotingRegressor\n",
    "\n",
    "def model_predictions(models, data):\n",
    "    X_test, y_test, X_train, y_train = data\n",
    "    y_preds = []\n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train) \n",
    "        y_pred = model.predict(X_test)\n",
    "        # to handle the dimensional issue for KRR\n",
    "        y_pred = y_pred.reshape(len(y_pred))\n",
    "        y_preds.append(y_pred)\n",
    "    return y_preds\n",
    "\n",
    "def avg_model_prediction(models, data):\n",
    "    y_preds = model_predictions(models, data)\n",
    "    y_preds = np.array([y_preds]).squeeze(axis = 0)\n",
    "    y_preds = y_preds.mean(axis = 0)\n",
    "    return y_preds\n",
    "\n",
    "def split_test_train(Data, indexes):\n",
    "    X, Y = Data\n",
    "    train_index, test_index = indexes\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "    return (X_test, y_test, X_train, y_train)\n",
    "\n",
    "def evalute_model_score(model):\n",
    "    scorer = make_scorer(r2_score, greater_is_better = True)\n",
    "    scores = cross_val_score(model, X, Y, cv = 5, scoring = scorer) \n",
    "    return scores\n",
    "\n",
    "def ensemble_bagging_R2(models, Data, k_fold = 5):\n",
    "    R_squares = []\n",
    "    kf = KFold(n_splits = k_fold)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        split_data = split_test_train(Data, (train_index, test_index))\n",
    "        y_pred = avg_model_prediction(models, split_data)\n",
    "        y_test = split_data[1]\n",
    "        R_squares.append(r2_score(y_test, y_pred))\n",
    "    return np.array([R_squares]).squeeze(axis=0)\n",
    "\n",
    "\n",
    "def ensemble_stacking_R2(models, Data, k_fold = 5):\n",
    "    R_squares = []\n",
    "    kf = KFold(n_splits = k_fold)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        split_data = split_test_train(Data, (train_index, test_index))\n",
    "        y_pred = avg_model_prediction(models, split_data)\n",
    "        y_test = split_data[1]\n",
    "        R_squares.append(r2_score(y_test, y_pred))\n",
    "    return np.array([R_squares]).squeeze(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVR_model = SVR(kernel = 'rbf', C = 5, epsilon = 0.2, gamma = 0.03)\n",
    "KRR_model = KernelRidge(kernel = 'laplacian', alpha = 0.07, gamma = 0.03)\n",
    "RFG_model = RandomForestRegressor(max_depth = 10, min_samples_split= 2, n_estimators = 50, random_state = 3)\n",
    "GBR_model = GradientBoostingRegressor(learning_rate = 0.1, loss = 'lad', max_depth = 30, min_samples_split = 6, n_estimators = 1000, random_state = 3)\n",
    "models = [SVR_model, KRR_model, GBR_model, RFG_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Perfomance of Each Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 of Support Vector Regression model is 0.41 with std 0.15\n",
      "The R2 of Kernel Ridge Regression model is 0.48 with std 0.07\n",
      "The R2 of Random Forest Regression model is 0.46 with std 0.10\n",
      "The R2 of Gradient Boosting Regression model is 0.48 with std 0.12\n"
     ]
    }
   ],
   "source": [
    "model_name = ['Support Vector Regression', 'Kernel Ridge Regression'\n",
    "              , 'Random Forest Regression', 'Gradient Boosting Regression']\n",
    "for i, model in enumerate(models):\n",
    "    scores = evalute_model_score(model)\n",
    "    print('The R2 of %s model is %.2f with std %.2f' %(model_name[i] ,scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the R2 of bagging method is 0.51 with std 0.11\n"
     ]
    }
   ],
   "source": [
    "Data = (X, Y)\n",
    "models = [SVR_model, KRR_model, GBR_model, RFG_model]\n",
    "bagging_scores = ensemble_bagging_R2(models, Data, k_fold = 5)\n",
    "print('the R2 of bagging method is %.2f with std %.2f' %(bagging_scores.mean(), bagging_scores.std())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = (X, Y)\n",
    "models = [SVR_model, KRR_model, GBR_model, RFG_model]\n",
    "stacking_scores = ensemble_stacking_R2(models, stack_model, Data, k_fold = 5)\n",
    "print('the R2 of stacking method is %.2f with std %.2f' %(stacking_scores.mean(), stacking_scores.std())) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
